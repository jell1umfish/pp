import requests
import pandas as pd
import xml.etree.ElementTree as ET
import json
from io import StringIO
from pymongo import MongoClient
from datetime import datetime

def log(msg):
    with open("logs.txt", "a", encoding="utf-8") as f:
        timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
        f.write(f"{timestamp} {msg}\n")
    print(msg)

def download_file(url):
    response = requests.get(url)
    if response.status_code == 200 and response.text.strip():
        return response.text
    else:
        log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {response.status_code} –∏–ª–∏ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
        return None

def parse_csv(data):
    """–ü–∞—Ä—Å–∏–Ω–≥ CSV-—Ñ–∞–π–ª–∞, –æ—á–∏—â–∞–µ–º –ø–æ–ª–µ Country."""
    df = pd.read_csv(StringIO(data), usecols=[0, 1, 3], names=["ID", "Name", "Country"], skiprows=1)
    
    # –û—á–∏—â–∞–µ–º –ø–æ–ª–µ Country: —É–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —Å–∫–æ–±–∫–∏ [
    df["Country"] = df["Country"].str.split("[").str[0].str.strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É Date
    df["Date"] = None
    
    return df


def parse_xml(data):
    try:
        root = ET.fromstring(data)
        records = []
        for entity in root.findall(".//Entity"):
            name = entity.find("Name").text if entity.find("Name") is not None else "Unknown"
            country = entity.find("Country").text if entity.find("Country") is not None else "Unknown"
            date = entity.find("Date").text if entity.find("Date") is not None else "Unknown"
            records.append({"Name": name, "Country": country, "Date": date})
        return pd.DataFrame(records)
    except ET.ParseError as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
        return pd.DataFrame()

def clean_data(df):
    df.drop_duplicates(inplace=True)
    df.dropna(subset=["Name", "Country"], inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

def save_to_mongo(df):
    client = MongoClient("mongodb://localhost:27017/")
    db = client["sanctions_db"]
    collection = db["sanctions_list"]
    data = df.to_dict(orient="records")
    collection.delete_many({})  # üí£ –û—á–∏—â–∞–µ–º –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
    collection.insert_many(data)
    log(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –≤ MongoDB")

def process_sanctions():
    sources = {
        "US": {
            "url": "https://www.treasury.gov/ofac/downloads/sdn.csv",
            "format": "csv"
        },
        "UK": {
            "url": "https://assets.publishing.service.gov.uk/media/67e51de1bb6002588a90d5d3/UK_Sanctions_List.xml",
            "format": "xml"
        }
    }

    all_data = []

    for source, info in sources.items():
        log(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ {source}...")
        data = download_file(info["url"])
        if data:
            if info["format"] == "csv":
                df = parse_csv(data)
            elif info["format"] == "xml":
                df = parse_xml(data)
            else:
                log(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {info['format']}")
                continue

            if not df.empty:
                df["Source"] = source
                all_data.append(df)

    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        cleaned_df = clean_data(combined_df)
        save_to_mongo(cleaned_df)
        cleaned_df.to_csv("sanctions_list_cleaned.csv", index=False, encoding="utf-8")
        log("üìÑ CSV —Ñ–∞–π–ª 'sanctions_list_cleaned.csv' —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
    else:
        log("‚ùå –û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ")

if __name__ == "__main__":
    process_sanctions()
